{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppunia74/INDE-577_Fall2022/blob/main/SupervisedLearning/5%20-%20Neural%20Network/MLP_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqgbfx91A4-V"
      },
      "source": [
        "# Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11c2oXTSA4-X"
      },
      "source": [
        "In this notebook, implementats a multilayered perceptron with a single input layer with $784$ input nodes, 2 hidden layers of arbitrary size, and $10$ output nodes. These layers will be denoted $L^0, L^1, L^2,$ and $L^{3}$, respectively. \n",
        "\n",
        "![MLP-2.png](https://github.com/ppunia74/INDE-577_Fall2022/blob/main/SupervisedLearning/5%20-%20Neural%20Network/Image/MLP_2.png)\n",
        "\n",
        "For $l = 1, 2, 3$, layer $l$ will have two phases:\n",
        "\n",
        "* The preactivation phase $z^l = W^la^{l-1} + b^l,$ \n",
        "* The postactivation phase $a^l = \\sigma(z^l).$ \n",
        "\n",
        "The preactivation phase includes a weighted linear combination of postactivation values in the previous layer. The postactivation values includes passing the preactivation value through a chosen activation function elementwise. For notational convience, let $a^0 = x$, where $x$ is the current input data into our network. This notebook use sigmoid function as the activation function.\n",
        "\n",
        "* Sigmoid Function\n",
        "$$\n",
        "\\sigma(s) = \\frac{1}{1+e^{-s}}.\n",
        "$$\n",
        "\n",
        "For our cost function, Mean Squared Error is used:\n",
        "$$\n",
        "C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n(a^i - y^i)^2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUUMDs3KA4-Y"
      },
      "source": [
        "### About the MNIST Data Set\n",
        "\n",
        "The MNIST data set consists of $70000$ images of hand written digits, $60000$ of which are typically used as labeled training examples, where the other $10000$ are used for testing your learning model on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X8F9AqMA4-Y"
      },
      "source": [
        "Each image in the MNIST data set is stored as a matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfP4n4kkA4-Y"
      },
      "source": [
        "### Goal\n",
        "\n",
        "To classify handwritten digits using the Multilayer Perceptron Learning algorithm based on the [MNIST data](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "\n",
        "### Tools\n",
        "\n",
        "This notebook uses the following libraries: \n",
        "\n",
        "* [matplotlib](http://metplotlib.org)\n",
        "* [numpy](https://numpy.org/doc/stable/index.html)\n",
        "* [tensorflow](https://www.tensorflow.org/)\n",
        "\n",
        "To load the MNIST data, we also need to import [keras.dataset](https://keras.io/api/datasets/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y9uAkNhNk8rR"
      },
      "outputs": [],
      "source": [
        "# Import the necessaty libraries\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stLONDz_A4-a"
      },
      "source": [
        "### Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7YjyCr3nA4-a",
        "outputId": "4db385be-8352-4f19-d3fb-d5e8c616575c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST data\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLMr5GoLoXOX",
        "outputId": "2e983c59-f723-4e3d-f967-d4c0889b8e59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# shape of the training set\n",
        "train_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnmX7oVroqnB",
        "outputId": "bd173c03-574a-42d8-990f-b578c964f5d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# shape of the first matrix in the training set\n",
        "train_X[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCz44XiPpQLx",
        "outputId": "6fb96857-630b-45ea-9528-181e7ced7738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# shape of the test set\n",
        "test_X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePXVR0LhA4-c"
      },
      "source": [
        "The training set has $60000$ pictures with $28 \\times 28$ pixel. The test set has $10000$ pictures with the same $28 \\times 28$ pixel. \n",
        "\n",
        "For a better understanding check the first data point in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "U500A41Goxyw",
        "outputId": "5739d901-50a4-4d99-f86e-077709e3d94d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f13ceba5410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# first matrix in the training set\n",
        "plt.imshow(train_X[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Bn_HlOouLx",
        "outputId": "60e7019e-6022-4d97-d324-40b79a2e8712"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# first label of the training set\n",
        "train_y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCna5zkaA4-c"
      },
      "source": [
        "The matrix and the label match. \n",
        "\n",
        "Examines, the range of the grey scale ($x$) in the training matrics. If the range is big, it may require scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNQ2bm7oo2mx",
        "outputId": "8738e658-2a6b-4c45-ab40-5153906e377b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.max(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "scJEuiz0A4-d",
        "outputId": "ee25fb4b-044b-4663-fd24-a18782a991ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.min(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6iWnw9JzA4-d",
        "outputId": "afb3c2c3-9d22-4f7d-b927-ed8bc950c14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.max(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YskPigidA4-d",
        "outputId": "f7c138c3-3bb8-4594-b93a-4412d3ae28e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "np.min(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waoGVMVqA4-e"
      },
      "source": [
        "The the range of the grey scale ($x$) is $(0, 255)$, and thus, require scaling. To scale it down divide by the maximun value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3mAE2bI2o-BB"
      },
      "outputs": [],
      "source": [
        "# Scale down X\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zljt7MrA4-e"
      },
      "source": [
        "Then we need to reshape the input matrics ($X$) and output matrics ($y$) to a desire pattern that can fit our algorithm.\n",
        "\n",
        "First, for the input matrics ($X$), we need to flatten the $28 \\times 28$ matrix, and reshape it to a $784 \\times 1$ vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FW-IrQORpSLw"
      },
      "outputs": [],
      "source": [
        "# X will temp store flattened matrices\n",
        "X = []\n",
        "for x in train_X:\n",
        "  X.append(x.flatten().reshape(784, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FftqLlqRA4-f"
      },
      "source": [
        "Second, for the output matrics ($y$), it is a single number, and we need to do the One Hot Encoding and represent it using a $10 \\times 1$ vector. For example, \n",
        "\n",
        "$$y=5 \\overset{\\text {One Hot encode}}{\\rightarrow} y =\\begin{bmatrix}\n",
        "0\\\\ \n",
        "0\\\\ \n",
        "0\\\\ \n",
        "0\\\\ \n",
        "0\\\\ \n",
        "1\\\\ \n",
        "0\\\\ \n",
        "0\\\\ \n",
        "0\\\\ \n",
        "0\n",
        "\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X7BxIFm8A4-f"
      },
      "outputs": [],
      "source": [
        "# Y will temp store one-hot encoded label vectors\n",
        "Y = []\n",
        "for y in train_y:\n",
        "  temp_vec = np.zeros((10, 1))\n",
        "  temp_vec[y][0] = 1.0\n",
        "  Y.append(temp_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yi7Zy32FA4-f"
      },
      "outputs": [],
      "source": [
        "# Our data will be stored as a list of tuples\n",
        "train_data = [p for p in zip(X, Y)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCa3KluOA4-f"
      },
      "source": [
        "So far, the \"train_data\" would have one column with the flattened $X$ vectors and the one column with the One Hot encoded label vectors. We can pick the first data point and print the One Hot encoded label and the original true value to check the transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90JMH_S57bih",
        "outputId": "0667c674-96e6-4c13-881e-858113f3f09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "p = train_data[0]\n",
        "print(p[1])\n",
        "print(train_y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn4gMG6_A4-g"
      },
      "source": [
        "The transformation is correct! Repeat the same thing on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KcZIVltbp_vv"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "for x in test_X:\n",
        "  X.append(x.flatten().reshape(784, 1))\n",
        "\n",
        "Y = []\n",
        "for y in test_y:\n",
        "  temp_vec = np.zeros((10, 1))\n",
        "  temp_vec[y][0] = 1.0\n",
        "  Y.append(temp_vec)\n",
        "\n",
        "test_data = [p for p in zip(X, Y)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3heeBJwzA4-g"
      },
      "source": [
        "---\n",
        "#### Activation Function\n",
        "Use the sigmoid function as the activation function, \n",
        "$$\\sigma(z)=\\frac {1}{1+e^{-z}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uQ2RvMV5qJsu"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "  return sigmoid(z)*(1.0-sigmoid(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3CSZ2xRA4-g"
      },
      "source": [
        "#### Loss Function\n",
        "Use the Mean Sqaure Error cost:\n",
        "$$\n",
        "C = C(W, b) = \\frac{1}{2}\\sum_{i=1}^n(a^i - y^i)^2.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JGa9ZA59A4-h"
      },
      "outputs": [],
      "source": [
        "def mse(a, y):\n",
        "  return .5*sum((a[i]-y[i])**2 for i in range(10))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sd2D-7oA4-h"
      },
      "source": [
        "#### The Function to Initialize the Weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c7iB08AIrCbc"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(layers = [784, 60, 60, 10]):\n",
        "  W = [[0.0]]  #add weight_0, to match the shape\n",
        "  B = [[0.0]]\n",
        "  for i in range(1, len(layers)):\n",
        "    w_temp = np.random.randn(layers[i], layers[i-1])*np.sqrt(2/layers[i-1])  #Scaling initializer to scale the shape\n",
        "    b_temp = np.random.randn(layers[i], 1)*np.sqrt(2/layers[i-1])\n",
        "\n",
        "    W.append(w_temp)\n",
        "    B.append(b_temp)\n",
        "  return W, B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o4RVAvCA4-h"
      },
      "source": [
        "Let's test!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2NrwX_wRrEx8"
      },
      "outputs": [],
      "source": [
        "W, B = initialize_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "m1Xn3ZXJrN57"
      },
      "outputs": [],
      "source": [
        "x, y = train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjHyL9mfA4-i"
      },
      "source": [
        "First layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "G1cBt3SotSqZ"
      },
      "outputs": [],
      "source": [
        "a0 = x\n",
        "z1 = (W[1] @ a0) + B[1]\n",
        "a1 = sigmoid(z1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dflUcRI-BpL",
        "outputId": "56cb49e0-dd3b-4b8d-9e4c-0608b7fb1451"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "a1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uyc22pUA4-i"
      },
      "source": [
        "The shape of the output of the first layer match the desire dimension.\n",
        "\n",
        "Second layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89DswyFrtiT5",
        "outputId": "e0861348-429e-42b3-d41d-a1cd5754b649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 1)\n"
          ]
        }
      ],
      "source": [
        "z2 = (W[2] @ a1) + B[2]\n",
        "a2 = sigmoid(z2)\n",
        "print(a2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxDpII1VA4-j"
      },
      "source": [
        "The shape of the output of the second layer match the desire dimension.\n",
        "\n",
        "And the third layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uB0Mk4otizq",
        "outputId": "f2c405ab-e85f-404f-aa0d-94efee3f7635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n"
          ]
        }
      ],
      "source": [
        "z3 = (W[3] @ a2) + B[3]\n",
        "a3 = sigmoid(z3)\n",
        "print(a3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVqB1i8-A4-j"
      },
      "source": [
        "The shape of the output of the thired layer match the desire dimension.\n",
        "\n",
        "These results suggest that the \"innitialize_weights\" function works well. And then, we can put the input and output of the layers together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HdrA_7UOt5DX"
      },
      "outputs": [],
      "source": [
        "W, B = initialize_weights(layers=[784, 60, 60, 10])\n",
        "x, y = train_data[0]\n",
        "Z = [[0.0]]\n",
        "A = [x]\n",
        "L = len(B)\n",
        "for i in range(1, L):\n",
        "  z = (W[i] @ A[i-1]) + B[i]\n",
        "  a = sigmoid(z)\n",
        "\n",
        "  Z.append(z)\n",
        "  A.append(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfDMce7gA4-k"
      },
      "source": [
        "To check whether the loop works well, we can print the shape of the output of the layer before the last layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb0DO1EhurnG",
        "outputId": "df71391b-26ac-4883-cabe-6db9102389c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "A[-1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvKxI1dKA4-k"
      },
      "source": [
        "The shape is correct! Let's move on!\n",
        "\n",
        "#### Output Error\n",
        "\n",
        "The output error is\n",
        "\n",
        "$$\\delta^{l-1}=\\triangledown_{a^{l-1}}C \\otimes \\sigma'(z^{l-1})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3jAcb248uswW"
      },
      "outputs": [],
      "source": [
        "# Measure the output error\n",
        "deltas = dict()\n",
        "delta_last = (A[-1] - y)*sigmoid_prime(Z[-1])\n",
        "deltas[L-1] = delta_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ7zYBAHBWDd",
        "outputId": "727d892a-f17f-40c1-f164-bb804e2cf597"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.13690736],\n",
              "       [ 0.14785847],\n",
              "       [ 0.13930474],\n",
              "       [ 0.14756446],\n",
              "       [ 0.01439897],\n",
              "       [-0.06833338],\n",
              "       [ 0.13817035],\n",
              "       [ 0.06482927],\n",
              "       [ 0.13228076],\n",
              "       [ 0.14785341]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "deltas[L-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_uCo8_6A4-l"
      },
      "source": [
        "#### Neuron Error\n",
        "\n",
        "According to the output error, for $l=L-2,...,1$, the neuron error is\n",
        "\n",
        "$$\\delta^{l}=\\left ( (w^{l+1})^T a^{l+1} \\right ) \\otimes \\sigma'(z^{l})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3M5rIEebvg90"
      },
      "outputs": [],
      "source": [
        "# calculate the neuron error\n",
        "for l in range(L-2, 0, -1):\n",
        "  deltas[l] = (W[l+1].T @ deltas[l+1])*sigmoid_prime(Z[l])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms6IMLOIvhqW",
        "outputId": "1ee3ac65-43a4-47d6-b555-dce5278e9499"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "deltas[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "K_RhQbiJA4-m",
        "outputId": "54253885-a81a-40c0-b615-7c890afd8b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "deltas[2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iyBoovhIA4-m",
        "outputId": "83802a0e-55f7-4bdb-9522-2df8be969585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "deltas[3].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq4yPTs7A4-m"
      },
      "source": [
        "The dimensions of the outputs of the layers are all correctly, suggesting that the codes for the output error and the neuron error work correctly.\n",
        "\n",
        "The gradient descent will be used to optimize the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wDGqFoFQwTqE"
      },
      "outputs": [],
      "source": [
        "# Set the learning rate\n",
        "alpha = 0.04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HKCHpDeVwgtj"
      },
      "outputs": [],
      "source": [
        "# To update the weights and bias\n",
        "for i in range(1, 4):\n",
        "  W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
        "  B[i] = B[i] - alpha*deltas[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2THvR1NaA4-n"
      },
      "source": [
        "#### Feedforward Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "K8mHDPhiwxC0"
      },
      "outputs": [],
      "source": [
        "def forward_pass(W, B, p, predict_vector = False):\n",
        "  Z =[[0.0]]\n",
        "  A = [p[0]]\n",
        "  L = len(W)\n",
        "  for i in range(1, L):\n",
        "    z = (W[i] @ A[i-1]) + B[i]\n",
        "    a = sigmoid(z)\n",
        "\n",
        "    Z.append(z)\n",
        "    A.append(a)\n",
        "\n",
        "  if predict_vector == True:\n",
        "    return A[-1]\n",
        "  else:\n",
        "    return Z, A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzgwlrGjA4-n"
      },
      "source": [
        "#### Store the Neuron Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cT86kfr6A4-n"
      },
      "outputs": [],
      "source": [
        "def deltas_dict(W, B, p):\n",
        "  Z, A = forward_pass(W, B, p)\n",
        "  L = len(W)\n",
        "  deltas = dict()\n",
        "  deltas[L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
        "  for l in range(L-2, 0, -1):\n",
        "    deltas[l] = (W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
        "\n",
        "  return A, deltas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEc936sVA4-o"
      },
      "source": [
        "#### Average of Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nayiEoIVyepQ"
      },
      "outputs": [],
      "source": [
        "def MSE(W, B, data):\n",
        "  c = 0.0\n",
        "  for p in data:\n",
        "    a = forward_pass(W, B, p, predict_vector=True)\n",
        "    c += mse(a, p[1])\n",
        "  return c/len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHSMbMijA4-o"
      },
      "source": [
        "---\n",
        "\n",
        "### Implement the Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF7uMRvUzO3w",
        "outputId": "c96fa858-0389-446c-a5c3-625ab6be86f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.7497447096850747\n"
          ]
        }
      ],
      "source": [
        "# Calculate the initial cost\n",
        "W, B = initialize_weights()\n",
        "print(f\"Initial Cost = {MSE(W, B, train_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jioHLhRrzcow",
        "outputId": "c57d2578-49dc-4926-f7df-f8ce23d46243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value = 0\n",
            "Actual Value = 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Show the performance\n",
        "i = np.random.randint(0, len(test_X))\n",
        "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector=True))\n",
        "print(f\"Predicted Value = {prediction}\")\n",
        "print(f\"Actual Value = {test_y[i]}\")\n",
        "plt.imshow(test_X[i], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8tlM9lvA4-p"
      },
      "source": [
        "The prediction is wrong. \n",
        "\n",
        "Next, train the model using Stochasitc Gradient Descent method.\n",
        "\n",
        "#### Stochasitc Gradient Descent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F-Ggl8gj0VW-"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(W, B, data, alpha = 0.04, epochs = 3):\n",
        "  L = len(W)\n",
        "  print(f\"Initial Cost = {MSE(W, B, data)}\")\n",
        "  for k in range(epochs):\n",
        "    for p in data:\n",
        "      A, deltas = deltas_dict(W, B, p)\n",
        "      for i in range(1, L):\n",
        "        W[i] = W[i] - alpha*deltas[i]@A[i-1].T\n",
        "        B[i] = B[i] - alpha*deltas[i]\n",
        "    print(f\"{k} Cost = {MSE(W, B, data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "X1iRbNB1A4-p",
        "outputId": "7c9e1821-c028-4088-97a5-27aa9cb113dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.7497447096850747\n",
            "0 Cost = 0.07488218738097913\n",
            "1 Cost = 0.053954013403380935\n",
            "2 Cost = 0.04306585487604781\n"
          ]
        }
      ],
      "source": [
        "stochastic_gradient_descent(W, B, train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OR1hsLIA4-q"
      },
      "source": [
        "The costs of every epoch gradually decrease. The training process works well.\n",
        "\n",
        "One example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bT68icm1A4-q",
        "outputId": "60793c31-e57f-4f44-9ef5-69f58f581c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Value = 0\n",
            "Actual Value = 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "i = np.random.randint(0, len(test_X))\n",
        "prediction = np.argmax(forward_pass(W, B, test_data[i], predict_vector=True))\n",
        "print(f\"Predicted Value = {prediction}\")\n",
        "print(f\"Actual Value = {test_y[i]}\")\n",
        "plt.imshow(test_X[i], cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVl4MpD2A4-q"
      },
      "source": [
        "The prediction matches the true label.\n",
        "\n",
        "Put all the functions together to make a class. Also, use **mini-batch gradient descent** to optimize the algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WCsZvETL0fk-"
      },
      "outputs": [],
      "source": [
        "class MultilayerPerceptron():\n",
        "  \n",
        "  def __init__(self, layers = [784, 60, 60, 10]):\n",
        "    self.layers = layers\n",
        "    self.L = len(self.layers)\n",
        "    self.W =[[0.0]]\n",
        "    self.B = [[0.0]]\n",
        "    for i in range(1, self.L):\n",
        "      w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
        "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
        "\n",
        "      self.W.append(w_temp)\n",
        "      self.B.append(b_temp)\n",
        "\n",
        "  def reset_weights(self, layers = [784, 60, 60, 10]):\n",
        "    self.layers = layers\n",
        "    self.L = len(self.layers)\n",
        "    self.W = [[0.0]]\n",
        "    self.B = [[0.0]]\n",
        "    for i in range(1, self.L):\n",
        "      w_temp = np.random.randn(self.layers[i], self.layers[i-1])*np.sqrt(2/self.layers[i-1])\n",
        "      b_temp = np.random.randn(self.layers[i], 1)*np.sqrt(2/self.layers[i-1])\n",
        "\n",
        "      self.W.append(w_temp)\n",
        "      self.B.append(b_temp)\n",
        "\n",
        "\n",
        "  def forward_pass(self, p, predict_vector = False):\n",
        "    Z =[[0.0]]\n",
        "    A = [p[0]]\n",
        "    for i in range(1, self.L):\n",
        "      z = (self.W[i] @ A[i-1]) + self.B[i]\n",
        "      a = sigmoid(z)\n",
        "      Z.append(z)\n",
        "      A.append(a)\n",
        "\n",
        "    if predict_vector == True:\n",
        "      return A[-1]\n",
        "    else:\n",
        "      return Z, A\n",
        "\n",
        "  def MSE(self, data):\n",
        "    c = 0.0\n",
        "    for p in data:\n",
        "      a = self.forward_pass(p, predict_vector=True)\n",
        "      c += mse(a, p[1])\n",
        "    return c/len(data)\n",
        "\n",
        "  def deltas_dict(self, p):\n",
        "    Z, A = self.forward_pass(p)\n",
        "    deltas = dict()\n",
        "    deltas[self.L-1] = (A[-1] - p[1])*sigmoid_prime(Z[-1])\n",
        "    for l in range(self.L-2, 0, -1):\n",
        "      deltas[l] = (self.W[l+1].T @ deltas[l+1]) * sigmoid_prime(Z[l])\n",
        "\n",
        "    return A, deltas\n",
        "\n",
        "  def stochastic_gradient_descent(self, data, alpha = 0.04, epochs = 3):\n",
        "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
        "    for k in range(epochs):\n",
        "      for p in data:\n",
        "        A, deltas = self.deltas_dict(p)\n",
        "        for i in range(1, self.L):\n",
        "          self.W[i] = self.W[i] - alpha*deltas[i]@A[i-1].T\n",
        "          self.B[i] = self.B[i] - alpha*deltas[i]\n",
        "    print(f\"{k} Cost = {self.MSE(data)}\")\n",
        "\n",
        "    \n",
        "  def mini_batch_gradient_descent(self, data, batch_size = 15, alpha = 0.04, epochs = 3):\n",
        "    print(f\"Initial Cost = {self.MSE(data)}\")\n",
        "    data_length = len(data)\n",
        "    for k in range(epochs):\n",
        "        for j in range(0, data_length-batch_size, batch_size):\n",
        "            delta_list = []\n",
        "            A_list = []\n",
        "            for p in data[j:j+batch_size]:\n",
        "                A, deltas = self.deltas_dict(p)\n",
        "                delta_list.append(deltas)\n",
        "                A_list.append(A)\n",
        "                \n",
        "                for i in range(1, self.L):\n",
        "                    self.W[i] = self.W[i] - (alpha/batch_size)*sum(da[0][i]@da[1][i-1].T for da in zip(delta_list, A_list))\n",
        "                    self.B[i] = self.B[i] - (alpha/batch_size)*sum(deltas[i] for deltas in delta_list)\n",
        "    print(f\"{k} Cost = {self.MSE(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzb0pgstA4-q"
      },
      "source": [
        "Let's try our class!\n",
        "\n",
        "We can also setup 60 nodes for both hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JHxk-iGLHzEG"
      },
      "outputs": [],
      "source": [
        "net = MultilayerPerceptron(layers=[784, 60, 60, 10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdH4zqk9A4-r"
      },
      "source": [
        "To use the stochastic gradient descent strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wSPs133H_HT",
        "outputId": "3eeb52fd-4492-48b1-b595-0e5e0127bf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 1.81203426530237\n",
            "2 Cost = 0.04181414484983884\n"
          ]
        }
      ],
      "source": [
        "net.stochastic_gradient_descent(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh6NpXJwA4-s"
      },
      "source": [
        "To use the mini-batch gradient descent strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "eJVa0rfEIBXj",
        "outputId": "15854e6e-3f97-4dab-ee41-863944c57888",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Cost = 0.04181414484983884\n",
            "2 Cost = 0.030973441830049804\n"
          ]
        }
      ],
      "source": [
        "net.mini_batch_gradient_descent(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06e44z-BA4-s"
      },
      "source": [
        "Between mini-batch gradient descent and stochastic gradient descent, mini-batch gradient descent has a smaller cost.\n",
        "\n",
        "However, the mini-batch gradient descent requires more resources and takes a longer time to compute."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "MLP_Good.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('inde577')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "fe327417f3aa4b34985ac31d7830e45cf068e03f2950d6797f271c4c708829c8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}